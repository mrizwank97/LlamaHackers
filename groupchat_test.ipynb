{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "\n",
    "config_list = [\n",
    "  {\n",
    "    \"model\": \"llama-3.2-3b-preview\",\n",
    "    \"base_url\": \"https://api.groq.com/openai/v1/chat/completions\",\n",
    "    \"api_type\": \"groq\",\n",
    "    \"api_key\": api_key,\n",
    "    \"api_rate_limit\": 2,\n",
    "  }\n",
    "]\n",
    "\n",
    "llm_config = config_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Write a blogpost about the stock price performance of \"\\\n",
    "\"Nvidia in the past month. Today's date is 2024-04-23.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy = autogen.ConversableAgent(\n",
    "    name=\"Admin\",\n",
    "    system_message=\"Give the task, and send \"\n",
    "    \"instructions to writer to refine the blog post.\",\n",
    "    code_execution_config=False,\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"ALWAYS\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = autogen.ConversableAgent(\n",
    "    name=\"Planner\",\n",
    "    system_message=\"Given a task, please determine \"\n",
    "    \"what information is needed to complete the task. \"\n",
    "    \"Please note that the information will all be retrieved using\"\n",
    "    \" Python code. Please only suggest information that can be \"\n",
    "    \"retrieved using Python code. \"\n",
    "    \"After each step is done by others, check the progress and \"\n",
    "    \"instruct the remaining steps. If a step fails, try to \"\n",
    "    \"workaround\",\n",
    "    description=\"Planner. Given a task, determine what \"\n",
    "    \"information is needed to complete the task. \"\n",
    "    \"After each step is done by others, check the progress and \"\n",
    "    \"instruct the remaining steps\",\n",
    "    llm_config=llm_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer = autogen.AssistantAgent(\n",
    "    name=\"Engineer\",\n",
    "    llm_config=llm_config,\n",
    "    description=\"An engineer that writes code based on the plan \"\n",
    "    \"provided by the planner.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = autogen.ConversableAgent(\n",
    "    name=\"Executor\",\n",
    "    system_message=\"Execute the code written by the \"\n",
    "    \"engineer and report the result.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 3,\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = autogen.ConversableAgent(\n",
    "    name=\"Writer\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Writer.\"\n",
    "    \"Please write blogs in markdown format (with relevant titles)\"\n",
    "    \" and put the content in pseudo ```md``` code block. \"\n",
    "    \"You take feedback from the admin and refine your blog.\",\n",
    "    description=\"Writer.\"\n",
    "    \"Write blogs based on the code execution results and take \"\n",
    "    \"feedback from the admin to refine the blog.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat = autogen.GroupChat(\n",
    "    agents=[user_proxy, engineer, writer, executor, planner],\n",
    "    messages=[],\n",
    "    max_round=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat, llm_config=llm_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
      "\n",
      "Write a blogpost about the stock price performance of Nvidia in the past month. Today's date is 2024-04-23.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m groupchat_result \u001b[38;5;241m=\u001b[39m \u001b[43muser_proxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\Desktop\\LlamaHackers\\venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1114\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1113\u001b[0m         msg2send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_init_message(message, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1114\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1115\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summarize_chat(\n\u001b[0;32m   1116\u001b[0m     summary_method,\n\u001b[0;32m   1117\u001b[0m     summary_args,\n\u001b[0;32m   1118\u001b[0m     recipient,\n\u001b[0;32m   1119\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\Desktop\\LlamaHackers\\venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:748\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    746\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m--> 748\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    751\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    752\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\Desktop\\LlamaHackers\\venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:914\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 914\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\Desktop\\LlamaHackers\\venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:2068\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[0;32m   2066\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[1;32m-> 2068\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[0;32m   2070\u001b[0m         log_event(\n\u001b[0;32m   2071\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2072\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2076\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[0;32m   2077\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\Desktop\\LlamaHackers\\venv\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:1171\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1170\u001b[0m     \u001b[38;5;66;03m# select the next speaker\u001b[39;00m\n\u001b[1;32m-> 1171\u001b[0m     speaker \u001b[38;5;241m=\u001b[39m \u001b[43mgroupchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_speaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n\u001b[0;32m   1173\u001b[0m         iostream \u001b[38;5;241m=\u001b[39m IOStream\u001b[38;5;241m.\u001b[39mget_default()\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\Desktop\\LlamaHackers\\venv\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:565\u001b[0m, in \u001b[0;36mGroupChat.select_speaker\u001b[1;34m(self, last_speaker, selector)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_agent(last_speaker)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# auto speaker selection with 2-agent chat\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_select_speaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_speaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\Desktop\\LlamaHackers\\venv\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:743\u001b[0m, in \u001b[0;36mGroupChat._auto_select_speaker\u001b[1;34m(self, last_speaker, selector, messages, agents)\u001b[0m\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_speaker_selection_transforms\u001b[38;5;241m.\u001b[39madd_to_agent(speaker_selection_agent)\n\u001b[0;32m    742\u001b[0m \u001b[38;5;66;03m# Run the speaker selection chat\u001b[39;00m\n\u001b[1;32m--> 743\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mchecking_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeaker_selection_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# don't use caching for the speaker selection chat\u001b[39;49;00m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_attempts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Limiting the chat to the number of attempts, including the initial one\u001b[39;49;00m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclear_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_speaker_auto_verbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Base silence on the verbose attribute\u001b[39;49;00m\n\u001b[0;32m    751\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_speaker_selection_result(result, last_speaker, agents)\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\Desktop\\LlamaHackers\\venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1107\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m msg2send \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1106\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1107\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_chat(recipient, clear_history)\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\Desktop\\LlamaHackers\\venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:748\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    746\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m--> 748\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    751\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    752\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\Desktop\\LlamaHackers\\venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:914\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 914\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\Desktop\\LlamaHackers\\venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:2068\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[0;32m   2066\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[1;32m-> 2068\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[0;32m   2070\u001b[0m         log_event(\n\u001b[0;32m   2071\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2072\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2076\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[0;32m   2077\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\Desktop\\LlamaHackers\\venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1436\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m messages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1435\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oai_messages[sender]\n\u001b[1;32m-> 1436\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_oai_reply_from_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_oai_system_message\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_cache\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, extracted_response)\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\Desktop\\LlamaHackers\\venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1455\u001b[0m, in \u001b[0;36mConversableAgent._generate_oai_reply_from_client\u001b[1;34m(self, llm_client, messages, cache)\u001b[0m\n\u001b[0;32m   1452\u001b[0m         all_messages\u001b[38;5;241m.\u001b[39mappend(message)\n\u001b[0;32m   1454\u001b[0m \u001b[38;5;66;03m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[1;32m-> 1455\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\n\u001b[0;32m   1457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1458\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m llm_client\u001b[38;5;241m.\u001b[39mextract_text_or_completion_object(response)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\Desktop\\LlamaHackers\\venv\\Lib\\site-packages\\autogen\\oai\\client.py:775\u001b[0m, in \u001b[0;36mOpenAIWrapper.create\u001b[1;34m(self, **config)\u001b[0m\n\u001b[0;32m    773\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# filter is not passed; try the next config\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 775\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_throttle_api_calls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    776\u001b[0m     request_ts \u001b[38;5;241m=\u001b[39m get_current_ts()\n\u001b[0;32m    777\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mcreate(params)\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\Desktop\\LlamaHackers\\venv\\Lib\\site-packages\\autogen\\oai\\client.py:1072\u001b[0m, in \u001b[0;36mOpenAIWrapper._throttle_api_calls\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_throttle_api_calls\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Rate limit api calls.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rate_limiters\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[0;32m   1073\u001b[0m         limiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rate_limiters[idx]\n\u001b[0;32m   1075\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m limiter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "groupchat_result = user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=task,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Plot a chart of NVDA and TESLA stock price change YTD.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "# filename: stock_price_change.py\n",
      "\n",
      "```python\n",
      "# Import necessary libraries\n",
      "import yfinance as yf\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Define the stock symbols\n",
      "stock_symbols = ['NVDA', 'TSLA']\n",
      "\n",
      "# Get the latest data for the given stocks\n",
      "data = {stock: yf.download(stock, period='2023-01-01', interval='1d')['Adj Close'] for stock in stock_symbols}\n",
      "\n",
      "# Create a DataFrame from the data\n",
      "df = pd.DataFrame(list(data.values()), columns=stock_symbols)\n",
      "\n",
      "# Calculate the YTD percentage change\n",
      "df['YTD'] = (df.iloc[:, 0] - df.iloc[0, 0]) / df.iloc[0, 0] * 100\n",
      "\n",
      "# Plot the chart\n",
      "plt.figure(figsize=(10,6))\n",
      "plt.plot(df.iloc[:, 0], label='NVDA')\n",
      "plt.plot(df.iloc[:, 1], label='TESLA')\n",
      "plt.title('Stock Price Change (YTD)')\n",
      "plt.xlabel('Date')\n",
      "plt.ylabel('Price ( Adj Close)')\n",
      "plt.legend()\n",
      "plt.show()\n",
      "```\n",
      "\n",
      "To run the code, make sure you have the required libraries installed (`yfinance` and `matplotlib`). Run the following command in your terminal to install the required libraries:\n",
      "```bash\n",
      "pip install yfinance matplotlib\n",
      "```\n",
      "If you have both pandas and matplotlib libraries, you do not need to install them.\n",
      "```\n",
      "python stock_price_change.py\n",
      "```\n",
      "This code will display a line chart with the YTD price change for NVDA and TESLA stocks.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"\", line 2, in <module>\n",
      "    import yfinance as yf\n",
      "ModuleNotFoundError: No module named 'yfinance'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "# filename: stock_price_change.py\n",
      "\n",
      "```python\n",
      "# Import necessary libraries\n",
      "import requests\n",
      "import json\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Define the stock symbols\n",
      "stock_symbols = ['NVDA', 'TSLA']\n",
      "\n",
      "# Define the API URL\n",
      "url = 'https://FinancialModelingPrep.com/api/v3/input'\n",
      "\n",
      "# Set the API key (replace with your actual API key)\n",
      "api_key = 'YOUR_API_KEY_HERE'\n",
      "\n",
      "# Get the latest data for the given stocks using the API\n",
      "headers = {\n",
      "    'apikey': api_key,\n",
      "    'function': 'VTDatenShowAll'\n",
      "}\n",
      "data = {\n",
      "    'Ticker': ','.join(stock_symbols),\n",
      "    'StartPeriod': '2023-01-01'\n",
      "}\n",
      "response = requests.post(url, headers=headers, json=data)\n",
      "\n",
      "# Check if the API request was successful\n",
      "if response.status_code == 200:\n",
      "    # Parse the JSON response\n",
      "    data = response.json()\n",
      "\n",
      "    # Extract the daily prices for the given stocks\n",
      "    daily_prices = data['Result']['Data']['NVDA']['DailyPrices']\n",
      "    tesla_daily_prices = data['Result']['Data']['TSLA']['DailyPrices']\n",
      "\n",
      "    # Create DataFrames from the daily prices\n",
      "    nvda_df = pd.DataFrame(daily_prices)\n",
      "    tesla_df = pd.DataFrame(tesla_daily_prices)\n",
      "\n",
      "    # Create a DataFrame with all the dates\n",
      "    dates = set(pd.to_datetime(nvda_df['Date']).to_list()) | set(pd.to_datetime(tesla_df['Date']).to_list())\n",
      "    dates = sorted(list(dates))\n",
      "    nvda Dates = pd.DataFrame({'Date': dates})\n",
      "    tesla Dates = pd.DataFrame({'Date': dates})\n",
      "\n",
      "    # Merge the data, filling missing date values for NVDA with NaN\n",
      "    merged_data = pd.merge(nvda Dates, nvda_df, on='Date', how='left', suffixes=('_NVDA', '_TESLA'))\n",
      "    merged_data = pd.merge(merged_data, tesla Dates, on='Date', how='left', suffixes=('_NVDA', '_TESLA'))\n",
      "\n",
      "    # Calculate the YTD percentage change for the given stocks\n",
      "    merged_data['YTD_NVDA'] = (merged_data['Close_NVDA'] - merged_data['Close_NVDA'].shift(1)) / merged_data['Close_NVDA'].shift(1) * 100\n",
      "    merged_data['YTD_TESLA'] = (merged_data['Close_TESLA'] - merged_data['Close_TESLA'].shift(1)) / merged_data['Close_TESLA'].shift(1) * 100\n",
      "\n",
      "# Plot the chart\n",
      "plt.figure(figsize=(10,6))\n",
      "plt.plot(merged_data['Close_NVDA'], label='NVDA')\n",
      "plt.plot(merged_data['Close_TESLA'], label='TESLA')\n",
      "plt.title('Stock Price Change (YTD)')\n",
      "plt.xlabel('Date')\n",
      "plt.ylabel('Price ( Adjusted Closing)')\n",
      "plt.legend()\n",
      "plt.show()\n",
      "```\n",
      "Replace `'YOUR_API_KEY_HERE'` with your actual API key. \n",
      "\n",
      "Please note that open APIs like this one may not be suitable for the task at hand. Finance APIs typically require checking the usage limits and getting a production plan before calling their endpoints.\n",
      "\n",
      "To run the code successfully, save the code in a file, install the necessary packages with pip, install an API key on the Financial Modeling Prep website and replace `'YOUR_API_KEY_HERE'` with your actual API key. Then run the code:\n",
      "\n",
      "```bash\n",
      "python stock_price_change.py\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "  File \"\", line 43\n",
      "    nvda Dates = pd.DataFrame({'Date': dates})\n",
      "         ^^^^^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "# filename: stock_price_change.py\n",
      "\n",
      "```python\n",
      "# Import necessary libraries\n",
      "import requests\n",
      "import json\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Define the stock symbols\n",
      "stock_symbols = ['NVDA', 'TSLA']\n",
      "\n",
      "# Define the API URL\n",
      "url = 'https://FinancialModelingPrep.com/api/v3/input'\n",
      "\n",
      "# Set the API key (replace with your actual API key)\n",
      "api_key = 'YOUR_API_KEY_HERE'\n",
      "\n",
      "# Get the latest data for the given stocks using the API\n",
      "headers = {\n",
      "    'apikey': api_key,\n",
      "    'function': 'VTDatenShowAll'\n",
      "}\n",
      "data = {\n",
      "    'Ticker': ','.join(stock_symbols),\n",
      "    'StartPeriod': '2023-01-01'\n",
      "}\n",
      "response = requests.post(url, headers=headers, json=data)\n",
      "\n",
      "# Check if the API request was successful\n",
      "if response.status_code == 200:\n",
      "    # Parse the JSON response\n",
      "    data = response.json()\n",
      "\n",
      "    # Extract the daily prices for the given stocks\n",
      "    daily_prices = data['Result']['Data']['NVDA']['DailyPrices']\n",
      "    tesla_daily_prices = data['Result']['Data']['TSLA']['DailyPrices']\n",
      "\n",
      "    # Create DataFrames from the daily prices\n",
      "    nvda_df = pd.DataFrame(daily_prices, columns=['Date', 'Close'])\n",
      "    tesla_df = pd.DataFrame(tesla_daily_prices, columns=['Date', 'Close'])\n",
      "\n",
      "    # Calculate the YTD percentage change for the given stocks\n",
      "    nvda_df['YTD'] = (nvda_df['Close'] - nvda_df['Close'].shift(1)) / nvda_df['Close'].shift(1) * 100\n",
      "    tesla_df['YTD'] = (tesla_df['Close'] - tesla_df['Close'].shift(1)) / tesla_df['Close'].shift(1) * 100\n",
      "\n",
      "    # Convert 'Date' column to datetime\n",
      "    nvda_df['Date'] = pd.to_datetime(nvda_df['Date'])\n",
      "    tesla_df['Date'] = pd.to_datetime(tesla_df['Date'])\n",
      "\n",
      "    # Merge the data, filling in missing date values for NVDA with NaN\n",
      "    merged_data = pd.merge(nvda_df, tesla_df, on='Date', how='left')\n",
      "\n",
      "    # Plot the chart\n",
      "    plt.figure(figsize=(10,6))\n",
      "    plt.plot(merged_data['Close_x'], label='NVDA')\n",
      "    plt.plot(merged_data['Close_y'], label='TESLA')\n",
      "    plt.title('Stock Price Change (YTD)')\n",
      "    plt.xlabel('Date')\n",
      "    plt.ylabel('Price ( Adjusted Closing)')\n",
      "    plt.legend()\n",
      "    plt.show()\n",
      "```\n",
      "Replace `'YOUR_API_KEY_HERE'` with your actual API key.\n",
      "\n",
      "Please note that open APIs like this one may not be suitable for the task at hand. Finance APIs typically require checking the usage limits and getting a production plan before calling their endpoints.\n",
      "\n",
      "To run the code successfully, save the code in a file, install the necessary packages with pip, install an API key on the Financial Modeling Prep website and replace `'YOUR_API_KEY_HERE'` with your actual API key. Then run the code:\n",
      "\n",
      "```bash\n",
      "python stock_price_change.py\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ahmad\\Desktop\\LlamaHackers\\venv\\Lib\\site-packages\\autogen\\oai\\groq.py:280: UserWarning: Cost calculation not available for model llama-3.2-3b-preview\n",
      "  warnings.warn(f\"Cost calculation not available for model {model}\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "\n",
    "api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "\n",
    "config_list = [\n",
    "  {\n",
    "    \"model\": \"llama-3.2-3b-preview\",\n",
    "    \"base_url\": \"https://api.groq.com/openai/v1/chat/completions\",\n",
    "    \"api_type\": \"groq\",\n",
    "    \"api_key\": api_key,\n",
    "  }\n",
    "]\n",
    "\n",
    "assistant = AssistantAgent(\"assistant\", llm_config={\"config_list\": config_list})\n",
    "\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", code_execution_config={\"work_dir\": \"coding\", \"use_docker\": False})\n",
    "chat_result = user_proxy.initiate_chat(assistant, message=\"Plot a chart of NVDA and TESLA stock price change YTD.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# filename: stock_price_change.py\\n\\n```python\\n# Import necessary libraries\\nimport requests\\nimport json\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\n# Define the stock symbols\\nstock_symbols = ['NVDA', 'TSLA']\\n\\n# Define the API URL\\nurl = 'https://FinancialModelingPrep.com/api/v3/input'\\n\\n# Set the API key (replace with your actual API key)\\napi_key = 'YOUR_API_KEY_HERE'\\n\\n# Get the latest data for the given stocks using the API\\nheaders = {\\n    'apikey': api_key,\\n    'function': 'VTDatenShowAll'\\n}\\ndata = {\\n    'Ticker': ','.join(stock_symbols),\\n    'StartPeriod': '2023-01-01'\\n}\\nresponse = requests.post(url, headers=headers, json=data)\\n\\n# Check if the API request was successful\\nif response.status_code == 200:\\n    # Parse the JSON response\\n    data = response.json()\\n\\n    # Extract the daily prices for the given stocks\\n    daily_prices = data['Result']['Data']['NVDA']['DailyPrices']\\n    tesla_daily_prices = data['Result']['Data']['TSLA']['DailyPrices']\\n\\n    # Create DataFrames from the daily prices\\n    nvda_df = pd.DataFrame(daily_prices, columns=['Date', 'Close'])\\n    tesla_df = pd.DataFrame(tesla_daily_prices, columns=['Date', 'Close'])\\n\\n    # Calculate the YTD percentage change for the given stocks\\n    nvda_df['YTD'] = (nvda_df['Close'] - nvda_df['Close'].shift(1)) / nvda_df['Close'].shift(1) * 100\\n    tesla_df['YTD'] = (tesla_df['Close'] - tesla_df['Close'].shift(1)) / tesla_df['Close'].shift(1) * 100\\n\\n    # Convert 'Date' column to datetime\\n    nvda_df['Date'] = pd.to_datetime(nvda_df['Date'])\\n    tesla_df['Date'] = pd.to_datetime(tesla_df['Date'])\\n\\n    # Merge the data, filling in missing date values for NVDA with NaN\\n    merged_data = pd.merge(nvda_df, tesla_df, on='Date', how='left')\\n\\n    # Plot the chart\\n    plt.figure(figsize=(10,6))\\n    plt.plot(merged_data['Close_x'], label='NVDA')\\n    plt.plot(merged_data['Close_y'], label='TESLA')\\n    plt.title('Stock Price Change (YTD)')\\n    plt.xlabel('Date')\\n    plt.ylabel('Price ( Adjusted Closing)')\\n    plt.legend()\\n    plt.show()\\n```\\nReplace `'YOUR_API_KEY_HERE'` with your actual API key.\\n\\nPlease note that open APIs like this one may not be suitable for the task at hand. Finance APIs typically require checking the usage limits and getting a production plan before calling their endpoints.\\n\\nTo run the code successfully, save the code in a file, install the necessary packages with pip, install an API key on the Financial Modeling Prep website and replace `'YOUR_API_KEY_HERE'` with your actual API key. Then run the code:\\n\\n```bash\\npython stock_price_change.py\\n```\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_result.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
