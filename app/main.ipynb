{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import autogen\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_community.document_loaders.image import UnstructuredImageLoader\n",
    "from autogen import register_function\n",
    "from typing import Annotated, Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_files_in_directory(directory_path):\n",
    "    \n",
    "#     parsed_data = parse_pdfs(directory_path)\n",
    "\n",
    "#     # for filename in os.listdir(directory_path):\n",
    "#         # file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "#         # if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp')):\n",
    "#         #     loader = UnstructuredImageLoader(file_path)\n",
    "#         #     documents = loader.load()\n",
    "#         #     parsed_text = ' '.join([doc.page_content for doc in documents])\n",
    "\n",
    "#         # else:\n",
    "#         #     continue\n",
    "\n",
    "#         # parsed_data[filename] = parsed_text\n",
    "\n",
    "#     return parsed_data\n",
    "\n",
    "\n",
    "def parse_pdfs(directory:str =\"../data/\") -> dict:\n",
    "# def parse_pdfs(dir_path=\"../data/\"):\n",
    "    parsed_data = {}\n",
    "    loader = PyPDFDirectoryLoader(directory, extract_images=True)\n",
    "    documents = loader.load()\n",
    "    for page in documents:\n",
    "        if parsed_data.get(page.metadata[\"source\"]) is None:\n",
    "            parsed_data[page.metadata[\"source\"]] = [page.page_content]\n",
    "        else:\n",
    "            parsed_data[page.metadata[\"source\"]].append(page.page_content)\n",
    "    return parsed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"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\"\n",
    "\n",
    "config_list = [\n",
    "  {\n",
    "    \"model\": \"llama-3.2-3b-preview\",\n",
    "    \"base_url\": \"https://api.groq.com/openai/v1/chat/completions\",\n",
    "    \"api_type\": \"groq\",\n",
    "    \"api_key\": api_key,\n",
    "    \"api_rate_limit\": 100\n",
    "  }\n",
    "]\n",
    "\n",
    "# llm_config = config_list[0]\n",
    "llm_config={\"config_list\": config_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Parse the documents and classify each of them by a heading\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_proxy = autogen.ConversableAgent(\n",
    "#     name=\"Admin\",\n",
    "#     system_message=\"Give the task, and send instructions to doc_classifier to classify the documents in the data folder\",\n",
    "#     code_execution_config=False,\n",
    "#     llm_config=llm_config,\n",
    "#     human_input_mode=\"ALWAYS\",\n",
    "# )\n",
    "\n",
    "user_proxy = autogen.ConversableAgent(\n",
    "    name=\"User\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    human_input_mode=\"NEVER\",\n",
    "    # max_consecutive_auto_reply=10,\n",
    "    # code_execution_config={\n",
    "    #     \"work_dir\": \"code\",\n",
    "    #     \"use_docker\": False\n",
    "    # },\n",
    "    llm_config=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_parse_caller = autogen.ConversableAgent(\n",
    "    name=\"Doc Parse Caller\",\n",
    "    llm_config=llm_config,\n",
    "    description=\"A caller for parsing documents\",\n",
    "    system_message=\"You are a helpful AI assistant. Use the provided python function parse_pdfs(directory), to parse the documents at the directory '../data/'.\"\n",
    ")\n",
    "\n",
    "doc_parser = autogen.ConversableAgent(\n",
    "    name=\"Doc Parser\",\n",
    "    llm_config=llm_config,\n",
    "    # system_message=\"You are a helpful AI assistant as an executer that parses documents. If you receive a python call instruction, then you execute it, or else ignore the message.\"\n",
    ")\n",
    "\n",
    "doc_classifier = autogen.ConversableAgent(\n",
    "    name=\"Doc Classifier\",\n",
    "    llm_config=llm_config,\n",
    "    description=\"A classifier that classifies the text that has been parsed\",\n",
    "    system_message=\"You are a helpful AI assistant.\"\n",
    "                   \"For each document provided, categorize them from one of these options ['Passport', 'Residence Permit', 'Transaction', 'Health Insurance', 'Other'].\"\n",
    "                   \"Reply TERMINATE when the task is done.\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.parse_pdfs(directory: str = '../data/') -> dict>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user_proxy.register_function(\n",
    "#     function_map={\n",
    "#         \"parse_pdfs\": parse_pdfs()\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# register_function(\n",
    "#     parse_pdfs,\n",
    "#     caller=doc_parse_caller,  \n",
    "#     executor=doc_parser,  \n",
    "#     name=\"parse_pdfs\",  \n",
    "#     description=\"A simple document parser\",  # A description of the tool.\n",
    "# )\n",
    "\n",
    "# Register the tool signature with the assistant agent.\n",
    "doc_parse_caller.register_for_llm(name=\"parse_pdfs\", description=\"A simple pdf parser\")(parse_pdfs)\n",
    "\n",
    "# Register the tool function with the user proxy agent.\n",
    "doc_parser.register_for_execution(name=\"parse_pdfs\")(parse_pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat = autogen.GroupChat(\n",
    "    agents=[user_proxy, doc_parser, doc_classifier],\n",
    "    messages=[],\n",
    "    max_round=5,\n",
    "    allowed_or_disallowed_speaker_transitions={\n",
    "        user_proxy: [doc_parser],\n",
    "        doc_parser: [doc_classifier],\n",
    "        doc_classifier: [],\n",
    "    },\n",
    "    speaker_transitions_type=\"allowed\",\n",
    ")\n",
    "\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'description': 'A simple pdf parser',\n",
       "   'name': 'parse_pdfs',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'directory': {'type': 'string',\n",
       "      'default': '../data/',\n",
       "      'description': 'directory'}},\n",
       "    'required': []}}}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_parse_caller.llm_config[\"tools\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_calling(recipient, messages, sender, config):\n",
    "    # return f\"Can you provide the python function to call for parsing the documents?\\n\\n {recipient.chat_messages_for_summary(sender)[-1]['content']}\"\n",
    "    #print(f\"{recipient.chat_messages_for_summary(sender)[-1]['content']}\")\n",
    "    return \"I have some pdf documents in the directory '../data/', and I would like to parse the documents in this directory\"\n",
    "\n",
    "\n",
    "doc_parser.register_nested_chats(\n",
    "    [\n",
    "        {\n",
    "            \"recipient\": doc_parse_caller,\n",
    "            \"message\": parse_calling,\n",
    "            \"max_turns\": 2,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        }\n",
    "    ],\n",
    "    trigger=manager,  # condition=my_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "I have some pdf documents in the directory '../data/', and I would like to know what type of documents they are (in terms of classification)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Doc Parser\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mDoc Parser\u001b[0m (to Doc Parse Caller):\n",
      "\n",
      "I have some pdf documents in the directory '../data/', and I would like to parse the documents in this directory\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDoc Parse Caller\u001b[0m (to Doc Parser):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_pp94): parse_pdfs *****\u001b[0m\n",
      "Arguments: \n",
      "{\"directory\": \"../data/\"}\n",
      "\u001b[32m*******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION parse_pdfs...\u001b[0m\n",
      "\u001b[33mDoc Parser\u001b[0m (to Doc Parse Caller):\n",
      "\n",
      "\u001b[33mDoc Parser\u001b[0m (to Doc Parse Caller):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_pp94) *****\u001b[0m\n",
      "{\"../data/Belgium RP.pdf\": [\"5133640 12\\nTREDE SEJOUR\\nRESIDENCE PERMIT\\nN REGISTRE NATI0NAL 95.07.30-528.34\\nREMARQUESIREMARKS\\nA.SEJOUR LIMITE\\nCAT.DU TITRE / TYPE OF PERMIT\\nF/F\\nSEX\\nSEXEI\\nKoumudiYasara-G\\nGANEPOLA ACHCHIGE\\nNOM Prenoms/SURNAME.Forenames\\nLKA\\nNATIONALITY\\nNATIONALITE\\n513364012\\nVALABLE JUSQU'AU /CARD EXPIRY\\n31 10 2023\\n30071995\\nDATE DE NAISSANCE\\nDATE OF BIRTH\", \"12102022\\nATEDEDELIVRANCE\\nETUDIANT\\nMARCHEDUTRAVAILLIMITE\\nREMARQUES/REMARKS\\nATEOFISSUE\\nGANEPOLAKACHCHIGE<<KOUMUDIKYAS\\n9507306F2310314LKA950730528348\\nIDBEL5133640129<<<<<<<<<<<<<<<\\nCOLOMBO\\nLIEU DE NAISSANCEI PLACE OF BIRTH\\nBRUXELLES\\nLIEU DE DELIVRANCE'I PLACE OF ISSUE\\n33A01\"]}\n",
      "\u001b[32m**************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mDoc Parse Caller\u001b[0m (to Doc Parser):\n",
      "\n",
      "It appears that the 'parse_pdfs' function is reading the PDFs and parsing the data in the form of key-value pairs. The keys seem to be the required field names such as 'N REGISTRE NATI0NAL', 'CAT.DU TITRE / TYPE OF PERMIT', etc. and the values are the corresponding data from the PDF. \n",
      "\n",
      "However, the output does not clearly separate the different keys and their corresponding values into a structured format, which would be more suitable for further analysis. \n",
      "\n",
      "To parse the data more effectively, you might need to further process the output of the 'parse_pdfs' function, for example, by splitting the data into different dictionaries or lists based on the keys, or by cleaning and normalizing the data.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mDoc Parser\u001b[0m (to chat_manager):\n",
      "\n",
      "It appears that the 'parse_pdfs' function is reading the PDFs and parsing the data in the form of key-value pairs. The keys seem to be the required field names such as 'N REGISTRE NATI0NAL', 'CAT.DU TITRE / TYPE OF PERMIT', etc. and the values are the corresponding data from the PDF. \n",
      "\n",
      "However, the output does not clearly separate the different keys and their corresponding values into a structured format, which would be more suitable for further analysis. \n",
      "\n",
      "To parse the data more effectively, you might need to further process the output of the 'parse_pdfs' function, for example, by splitting the data into different dictionaries or lists based on the keys, or by cleaning and normalizing the data.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Doc Classifier\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mDoc Classifier\u001b[0m (to chat_manager):\n",
      "\n",
      "Based on the provided information, I would categorize the documents as `'Other'`. This categorization is due to the presence of common field names such as 'N REGISTRE NATI0NAL' and 'CAT.DU TITRE / TYPE OF PERMIT' in the PDFs, which are typically found in forms related to nationality registration and permit applications. These structures are not typically classified under standard categories such as passport, residence permit, transaction, or health insurance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Doc Classifier\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mDoc Classifier\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koumudi/Documents/Llama_Hack/LlamaHackers/venv/lib/python3.12/site-packages/autogen/oai/groq.py:279: UserWarning: Cost calculation not available for model llama-3.2-3b-preview\n",
      "  warnings.warn(f\"Cost calculation not available for model {model}\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "Next speaker: User\n",
      "\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    # message=\"Parse the documents and classify each of them by a heading\",\n",
    "    message=\"I have some pdf documents in the directory '../data/', and I would like to know what type of documents they are (in terms of classification)\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
